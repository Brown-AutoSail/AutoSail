{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adc79ae2-51be-4ba4-be5b-0d0e00c7eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33865e54-4abc-4ab8-8d49-a7555023b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_optimisation(n_iters, sample_loss, bounds, n_pre_samples=5,\n",
    "                          random_search=False, alpha=1e-5, epsilon=1e-7):\n",
    "    \"\"\" \n",
    "    Uses Gaussian Processes to optimise the loss function `sample_loss`.\n",
    "    \"\"\"\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    " \n",
    "    for params in np.random.uniform(bounds[:, 0], bounds[:, 1], (n_pre_samples, bounds.shape[0])):\n",
    "        x_list.append(params)\n",
    "        y_list.append(sample_loss(params))\n",
    "\n",
    "\n",
    "    xp = np.array(x_list)\n",
    "    yp = np.array(y_list)\n",
    "\n",
    "    # Create the GP\n",
    "    kernel = gp.kernels.Matern()\n",
    "    model = gp.GaussianProcessRegressor(kernel=kernel,\n",
    "                                        alpha=alpha,\n",
    "                                            n_restarts_optimizer=10,\n",
    "                                            normalize_y=True)\n",
    "\n",
    "    for n in range(n_iters):\n",
    "\n",
    "        model.fit(xp, yp)\n",
    "\n",
    "        # Sample next hyperparameter\n",
    "        if random_search:\n",
    "            x_random = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(random_search, n_params))\n",
    "            ei = -1 * expected_improvement(x_random, model, yp, greater_is_better=True, n_params=n_params)\n",
    "            next_sample = x_random[np.argmax(ei), :]\n",
    "        else:\n",
    "            next_sample = sample_next_hyperparameter(expected_improvement, model, yp, greater_is_better=True, bounds=bounds, n_restarts=100)\n",
    "\n",
    "        # Duplicates will break the GP. In case of a duplicate, we will randomly sample a next query point.\n",
    "        if np.any(np.abs(next_sample - xp) <= epsilon):\n",
    "            next_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], bounds.shape[0])\n",
    "\n",
    "        # Sample loss for new set of parameters\n",
    "        cv_score = sample_loss(next_sample)\n",
    "\n",
    "        # Update lists\n",
    "        x_list.append(next_sample)\n",
    "        y_list.append(cv_score)\n",
    "\n",
    "        # Update xp and yp\n",
    "        xp = np.array(x_list)\n",
    "        yp = np.array(y_list)\n",
    "\n",
    "    return xp, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45b21e-5c40-4bb9-871f-f89d10bb915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_loss(params):\n",
    "    return cross_val_score(SVC(C=10 ** params[0], gamma=10 ** params[1], random_state=12345),\n",
    "                           X=data, y=target, scoring='roc_auc', cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15a61c-d7d9-4859-a123-e97f0035267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([[0, 10000], [0, 10000], [0, 10000],[0, 10000],[0, 10000]])\n",
    "\n",
    "xp, yp = bayesian_optimisation(n_iters=30, \n",
    "                               sample_loss=sample_loss, \n",
    "                               bounds=bounds,\n",
    "                               n_pre_samples=3,\n",
    "                               random_search=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2a8e8a8-3ec3-446d-9eda-d8c5c0f2490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"destination-rules.yaml\"\n",
    "kubectl_apply_cmd = \"kubectl apply -f \"\n",
    "\n",
    "class IstioConfig:\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "        with open(file_name, \"r\") as stream:\n",
    "            docs = yaml.load_all(stream, Loader=yaml.FullLoader)\n",
    "            self.docs = list(docs)\n",
    "    \n",
    "    # save to yaml file\n",
    "    def save(self):\n",
    "        with open(self.file_name, \"w\") as stream:\n",
    "            yaml.dump_all(self.docs, stream)\n",
    "    \n",
    "    # apply to Istio cluster\n",
    "    def apply(self):\n",
    "        self.save()\n",
    "        os.system(kubectl_apply_cmd + self.file_name)\n",
    "        \n",
    "    # reset to default config (does not save)\n",
    "    def reset(self):\n",
    "        for i in range(self.size()):\n",
    "            ic.docs[i][\"spec\"][\"trafficPolicy\"][\"connectionPool\"][\"http\"] = {}\n",
    "            ic.docs[i][\"spec\"][\"trafficPolicy\"][\"connectionPool\"][\"tcp\"] = {}\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.docs)\n",
    "    \n",
    "    def get_docs(self):\n",
    "        return self.docs\n",
    "    \n",
    "    def _get_http(self, i):\n",
    "        return ic.docs[i][\"spec\"][\"trafficPolicy\"][\"connectionPool\"][\"http\"]\n",
    "    \n",
    "    def _get_tcp(self, i):\n",
    "        return ic.docs[i][\"spec\"][\"trafficPolicy\"][\"connectionPool\"][\"tcp\"]\n",
    "    \n",
    "    #### tcp ####\n",
    "    # maxConnections: int32\n",
    "    # 100\n",
    "    def set_tcp_max_connections(self, i, val):\n",
    "        self._get_tcp(i)[\"maxConnections\"] = val\n",
    "    \n",
    "    # connectTimeout: int (unit ms)\n",
    "    # 30\n",
    "    def set_tcp_connect_timeout(self, i, val):\n",
    "        self._get_tcp(i)[\"connectTimeout\"] = str(val) + \"ms\"\n",
    "        \n",
    "    # TcpKeepalive time: int (unit ms)\n",
    "    # \n",
    "    def set_tcp_keeplive_probes(self, i, val):\n",
    "        val = str(val) + \"ms\"\n",
    "        tcp = self._get_tcp(i)\n",
    "        if \"tcpKeepalive\" in tcp:\n",
    "            tcp[\"tcpKeepalive\"][\"time\"] = val\n",
    "        else:\n",
    "            tcp[\"tcpKeepalive\"] = {\"time\": val}\n",
    "            \n",
    "    # TcpKeepalive time: int (unit ms)\n",
    "    # 7200s\n",
    "    def set_tcp_keeplive_time(self, i, val):\n",
    "        val = str(val) + \"ms\"\n",
    "        tcp = self._get_tcp(i)\n",
    "        if \"tcpKeepalive\" in tcp:\n",
    "            tcp[\"tcpKeepalive\"][\"time\"] = val\n",
    "        else:\n",
    "            tcp[\"tcpKeepalive\"] = {\"time\": val}\n",
    "            \n",
    "    # TcpKeepalive interval: int (unit ms)\n",
    "    # 75s\n",
    "    def set_tcp_keeplive_interval(self, i, val):\n",
    "        val = str(val) + \"ms\"\n",
    "        tcp = self._get_tcp(i)\n",
    "        if \"tcpKeepalive\" in tcp:\n",
    "            tcp[\"tcpKeepalive\"][\"interval\"] = val\n",
    "        else:\n",
    "            tcp[\"tcpKeepalive\"] = {\"interval\": val}\n",
    "    \n",
    "    #### http ####\n",
    "    # http1MaxPendingRequests: int32\n",
    "    def set_http_http1_max_pending_requests(self, i, val):\n",
    "        self._get_http(i)[\"http1MaxPendingRequests\"] = val\n",
    "    \n",
    "    # http2MaxRequests: int32\n",
    "    def set_http_http2_max_requests(self, i, val):\n",
    "        self._get_http(i)[\"http2MaxRequests\"] = val\n",
    "    \n",
    "    # maxRequestsPerConnection: int32\n",
    "    def set_http_max_requests_per_connection(self, i, val):\n",
    "        self._get_http(i)[\"maxRequestsPerConnection\"] = val\n",
    "        \n",
    "    # maxRetries: int32\n",
    "    def set_http_max_retries(self, i, val):\n",
    "        self._get_http(i)[\"maxRetries\"] = val\n",
    "    \n",
    "    # idleTimeout : int (unit ms)\n",
    "    def set_http_idle_timeout(self, i, val):\n",
    "        self._get_http(i)[\"idleTimeout\"] = str(val) + \"ms\"\n",
    "        \n",
    "    # useClientProtocol: bool\n",
    "    def set_http_use_client_protocol(self, i, val):\n",
    "        self._get_http(i)[\"useClientProtocol\"] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eadd5c6-6e92-4a19-9ce9-c05b8227719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_load(num_clients, num_reqs):\n",
    "    cmd = \"docker run load-test -h {url} -r {num_reqs} -c {num_clients}\".format(url = GATEWAY_URL, num_reqs = num_reqs, num_clients = num_clients)\n",
    "    return subprocess.getoutput(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f13a0e59-12e3-4e78-8ac1-ca0a226e28cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to listen on port 9090: Listeners failed to create with the following errors: [unable to create listener: Error listen tcp4 127.0.0.1:9090: bind: address already in use unable to create listener: Error listen tcp6 [::1]:9090: bind: address already in use]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:45649\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "\n",
    "prometheus_host_cmd = [\"/home/jupyter/.istioctl/bin/istioctl\", \"dashboard\", \"prometheus\"]\n",
    "prometheus_host = \"http://localhost:9090\"\n",
    "\n",
    "# start a local Prometheus host\n",
    "host = subprocess.Popen(prometheus_host_cmd)\n",
    "client = PrometheusConnect(url =prometheus_host, disable_ssl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1be45102-2312-479d-ac0c-f9de41e3efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PrometheusConnect(url =\"http://localhost:45649\", disable_ssl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d12e152-f622-44a4-b2eb-0921ea5762cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GATEWAY_URL = '34.133.80.64:80'\n",
    "config_file = \"destination-rules.yaml\"\n",
    "kubectl_apply_cmd = \"kubectl apply -f \"\n",
    "ic = IstioConfig(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76169799-21df-4070-9ffb-dcfb39dbd46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "def generate_data(ic, prometheus_client, num_data, num_clients, num_reqs, config_upper_bound):\n",
    "        '''\n",
    "            randomly config the istio\n",
    "            generate load with {num_clients} clients and {num_reqs} requests\n",
    "            save the performance from Prometheus\n",
    "            repeat {num_data} times and get {num_data} data\n",
    "            \n",
    "            @return states, latencies\n",
    "        '''\n",
    "        NUM_ENDPOINTS = 14\n",
    "        \n",
    "        states = []\n",
    "        performances = []\n",
    "        \n",
    "        # randomly config the istio\n",
    "        ic.reset()\n",
    "        \n",
    "        for i in range(NUM_ENDPOINTS):\n",
    "            if i != 4:\n",
    "                random_vals = random.sample(range(1, config_upper_bound), 6)\n",
    "                ic.set_tcp_max_connections(i, random_vals[0])\n",
    "                ic.set_tcp_connect_timeout(i, random_vals[1])\n",
    "                ic.set_http_http1_max_pending_requests(i, random_vals[2])\n",
    "                ic.set_http_http2_max_requests(i, random_vals[3])\n",
    "                ic.set_http_max_requests_per_connection(i, random_vals[4])\n",
    "                ic.set_http_max_retries(i, random_vals[5])\n",
    "                states.append(random_vals)\n",
    "\n",
    "        ic.apply()\n",
    "        \n",
    "        # generate load\n",
    "        print(\"num clients {}, num reqs {}\".format(num_clients, num_reqs))\n",
    "        \n",
    "        output = generate_load(num_clients, num_reqs)\n",
    "        #print(output)\n",
    "        time.sleep(3)\n",
    "        metrics = prometheus_client.custom_query(query=\"microservices_demo_user_request_latency_microseconds\")\n",
    "        if len(metrics) > 0:\n",
    "            latencies_99_quantile = list([float(metrics[i]['value'][1]) for i in [2,5,8,14]])\n",
    "        else:\n",
    "            # cannot fetch performance metrics\n",
    "            latencies_99_quantile = [float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\")]\n",
    "        performances.append(latencies_99_quantile)\n",
    "        \n",
    "        return states, performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c808a812-9705-42dd-81e1-545bd3ae71f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destinationrule.networking.istio.io/carts configured\n",
      "destinationrule.networking.istio.io/carts-db configured\n",
      "destinationrule.networking.istio.io/catalogue configured\n",
      "destinationrule.networking.istio.io/catalogue-db configured\n",
      "destinationrule.networking.istio.io/front-end unchanged\n",
      "destinationrule.networking.istio.io/orders configured\n",
      "destinationrule.networking.istio.io/orders-db configured\n",
      "destinationrule.networking.istio.io/payment configured\n",
      "destinationrule.networking.istio.io/queue-master configured\n",
      "destinationrule.networking.istio.io/rabbitmq configured\n",
      "destinationrule.networking.istio.io/session-db configured\n",
      "destinationrule.networking.istio.io/shipping configured\n",
      "destinationrule.networking.istio.io/user configured\n",
      "destinationrule.networking.istio.io/user-db configured\n",
      "num clients 10, num reqs 200\n"
     ]
    }
   ],
   "source": [
    "states, latencies = generate_data(ic, client, 10, 10, 200, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a81893a-d856-4c58-af5a-ab0e20e317aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.00926263, 0.010547914, 0.010141945000000001, 0.016321986]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e4bdb-1ce7-4eb8-83bd-8209beaaffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Define the hyperparameter configuration space\n",
    "tune_params = {\n",
    "    'http1MaxPendingRequests': sp_randint(0,10000), #2^32-1\n",
    "    \"http2MaxRequests\":sp_randint(0,10000),\n",
    "    'maxRequestsPerConnection': sp_randint(0,10000),\n",
    "    \"maxRetries\":sp_randint(0,10000),\n",
    "    \"maxConnections\":sp_randint(0,10000),\n",
    "    # \"idleTimeout\":sp_randint(0,1000)\n",
    "    # \"useClientProtocol\":['mse','mae']\n",
    "}\n",
    "n_iter_search=20 #number of iterations is set to 20, you can increase this number if time permits\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "Random = RandomizedSearchCV(clf, param_distributions=tune_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676cfda1-a481-49f6-85cf-cbe18b9ec4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Define the hyperparameter configuration space\n",
    "tune_params = {\n",
    "    'test1': sp_randint(0,10), #2^32-1\n",
    "    \"test2\":sp_randint(0,10),\n",
    "}\n",
    "n_iter_search=20 #number of iterations is set to 20, you can increase this number if time permits\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "Random = RandomizedSearchCV(clf, param_distributions=tune_params,n_iter=n_iter_search,cv=3,scoring='neg_mean_squared_error')\n",
    "Random.fit(X, y)\n",
    "print(Random.best_params_)\n",
    "print(\"MSE:\"+ str(-Random.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22347bd2-3978-4c23-8048-90506ef17021",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [0.013327259000000001, 0.014051314, 0.013654487000000002, 0.033338778]\n",
    "l2 = [0.012540949000000001, 0.013926724000000001, 0.013654487000000002, 0.030811651000000002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "010aa1d0-20d6-468c-96e6-11ab01301bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0185929595"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(l1) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e84f74b9-766a-4675-a070-1becb64391d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017733452750000003"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(l2) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c898349-5ad8-4f47-8006-a7356317dede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008595067499999956"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "0.0185929595 - 0.017733452750000003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da71b35f-f75d-4e34-9957-ad6259a7826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046227538440020574"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-13T01:14:20.712763Z\terror\tklog\tlost connection to pod\n"
     ]
    }
   ],
   "source": [
    "0.0008595067499999956 / 0.0185929595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28194321-59b2-4033-898b-53191fbee8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
